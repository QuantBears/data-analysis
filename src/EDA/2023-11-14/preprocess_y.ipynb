{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "accessKeys = pd.read_csv(\"../../quant-bears_accessKeys.csv\")\n",
    "session = boto3.Session(\n",
    "\taws_access_key_id=accessKeys.loc[0, \"Access key ID\"],\n",
    "\taws_secret_access_key=accessKeys.loc[0, \"Secret access key\"]\n",
    ")\n",
    "\n",
    "s3_collection_path = \"s3://quant-bears-data-collection/raw-data/\"\n",
    "s3_price_collection_path = \"s3://quant-bears-data-collection/raw-resolved-price/\"\n",
    "\n",
    "def load_data():\n",
    "\tdata_sources = [\"seekingAlpha.seekingAlphaBulkMetrics\", \"gurufocus\"]\n",
    "\tsources_dict = dict((source, wr.s3.list_objects(s3_collection_path + source + \"/\", boto3_session=session)) for source in data_sources)\n",
    "\tdf_dict = {}\n",
    "\tfor source in data_sources:\n",
    "\t\tdfs = []\n",
    "\t\tprint(source)\n",
    "\t\tfor path in tqdm(sources_dict[source]):\n",
    "\t\t\tnew_df = wr.s3.read_parquet(path, boto3_session=session)\n",
    "\t\t\tnew_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\t\t\tdfs.append(new_df)\n",
    "\n",
    "\t\tdf_dict[source] = pd.concat(dfs, axis = 0)\n",
    "\tjoined_df = pd.concat([df.set_index([\"date\", \"ticker\"]) for df in df_dict.values()], axis = 1)\n",
    "\treturn joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seekingAlpha.seekingAlphaBulkMetrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33 [00:00<?, ?it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      "  3%|▎         | 1/33 [00:00<00:26,  1.20it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      "  6%|▌         | 2/33 [00:01<00:29,  1.03it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      "  9%|▉         | 3/33 [00:02<00:26,  1.13it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 12%|█▏        | 4/33 [00:03<00:27,  1.05it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 15%|█▌        | 5/33 [00:04<00:26,  1.05it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 18%|█▊        | 6/33 [00:06<00:29,  1.10s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 21%|██        | 7/33 [00:07<00:30,  1.19s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 24%|██▍       | 8/33 [00:08<00:28,  1.15s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 27%|██▋       | 9/33 [00:09<00:26,  1.10s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 30%|███       | 10/33 [00:10<00:24,  1.06s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 33%|███▎      | 11/33 [00:11<00:21,  1.04it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 36%|███▋      | 12/33 [00:12<00:19,  1.08it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 39%|███▉      | 13/33 [00:13<00:19,  1.02it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 42%|████▏     | 14/33 [00:14<00:18,  1.01it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 45%|████▌     | 15/33 [00:14<00:16,  1.08it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 48%|████▊     | 16/33 [00:16<00:18,  1.09s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 52%|█████▏    | 17/33 [00:17<00:16,  1.06s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 55%|█████▍    | 18/33 [00:19<00:18,  1.23s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 58%|█████▊    | 19/33 [00:19<00:15,  1.13s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 61%|██████    | 20/33 [00:20<00:14,  1.08s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 64%|██████▎   | 21/33 [00:21<00:11,  1.02it/s]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 67%|██████▋   | 22/33 [00:23<00:13,  1.19s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 70%|██████▉   | 23/33 [00:24<00:11,  1.13s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 73%|███████▎  | 24/33 [00:25<00:10,  1.20s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 76%|███████▌  | 25/33 [00:27<00:10,  1.26s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 79%|███████▉  | 26/33 [00:27<00:07,  1.13s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 82%|████████▏ | 27/33 [00:28<00:06,  1.10s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 85%|████████▍ | 28/33 [00:29<00:05,  1.09s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 88%|████████▊ | 29/33 [00:30<00:04,  1.04s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 91%|█████████ | 30/33 [00:32<00:03,  1.20s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 94%|█████████▍| 31/33 [00:33<00:02,  1.03s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      " 97%|█████████▋| 32/33 [00:34<00:01,  1.15s/it]/var/folders/tq/51dxx6813y7g8dg44h973dmr0000gn/T/ipykernel_54658/1238645899.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
      "100%|██████████| 33/33 [00:35<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gurufocus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:20<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_pred_price(df, days_ahead=5):\n",
    "\tall_dates = df.index.get_level_values(0).unique()\n",
    "\tadjusted_dates = all_dates[:-days_ahead]\n",
    "\tadjusted_df = df.loc[adjusted_dates]\n",
    "\n",
    "\tpred_dates = all_dates[days_ahead:]\n",
    "\tdfs = []\n",
    "\tfor i, d in enumerate(tqdm(pred_dates)):\n",
    "\t\tpath = s3_price_collection_path + d + \".parquet\"\n",
    "\t\tnew_df = wr.s3.read_parquet(path, boto3_session=session)\n",
    "\n",
    "\t\ts = df.loc[all_dates[i], \"primary_price\"]\n",
    "\t\tintersect_tickers = np.intersect1d(new_df[\"ticker\"].values, s[~s.isna()].index.values)\n",
    "\t\tnew_df = new_df[new_df[\"ticker\"].isin(intersect_tickers)]\n",
    "\t\tnew_df[\"date\"] = all_dates[i]\n",
    "\t\tdfs.append(new_df)\n",
    "\n",
    "\tprice_df = pd.concat(dfs, axis = 0).set_index([\"date\", \"ticker\"]).rename({\"primary_price\": \"pred_price\"}, axis = 1)\n",
    "\treturn adjusted_df.reindex(price_df.index), price_df\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:12<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "adj_df, price_df = load_pred_price(df, days_ahead=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3451770"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df[\"pred_price\"] = price_df[\"pred_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2023-09-28', '2023-09-29', '2023-10-02', '2023-10-03', '2023-10-04',\n",
       "       '2023-10-05', '2023-10-06', '2023-10-09', '2023-10-10', '2023-10-11',\n",
       "       '2023-10-12', '2023-10-13', '2023-10-16', '2023-10-17', '2023-10-18',\n",
       "       '2023-10-19', '2023-10-20', '2023-10-24', '2023-10-25', '2023-10-26',\n",
       "       '2023-10-27', '2023-10-30', '2023-10-31', '2023-11-01', '2023-11-02',\n",
       "       '2023-11-03', '2023-11-06', '2023-11-07'],\n",
       "      dtype='object', name='date')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_df.index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "short_term_columns = ['analysts_down', 'analysts_down_percent', 'analysts_up_percent',\n",
    "       'authors_count', 'capm_alpha_60m', 'coefficient_of_variation_90d',\n",
    "       'debt_eq', 'div_growth_category', 'div_safety_category',\n",
    "       'dividends_estimate_fy1_analyst_down',\n",
    "       'dividends_estimate_fy1_analyst_up',\n",
    "       'dividends_estimate_fy2_analyst_down',\n",
    "       'dividends_estimate_fy2_analyst_up',\n",
    "       'dps_consensus_mean_percent_revisions_down_1_annual_period_fwd',\n",
    "       'eps_ltg', 'last_price_vs_sma_100d', 'last_price_vs_sma_10d',\n",
    "       'last_price_vs_sma_200d', 'last_price_vs_sma_50d', 'momentum_12m',\n",
    "       'momentum_3m', 'momentum_6m', 'momentum_9m', 'pb_ratio',\n",
    "       'price_return_1y', 'price_return_3m', 'price_return_6m',\n",
    "       'price_return_9m', 'return_on_net_tangible_assets',\n",
    "       'return_on_total_capital', 'Future_3-5Y_EPS_without_NRI_Growth_Rate',\n",
    "       'moment_rank', '5-Day_RSI', '9-Day_RSI', '14-Day_RSI',\n",
    "       '6-1_Month_Momentum_%', '12-1_Month_Momentum_%', 'ratios_rank',\n",
    "       'Forward_PE_Ratio', 'EV-to-Forward-EBITDA',\n",
    "       'Earnings_Yield__Greenblatt__%', 'Volume']\n",
    "\n",
    "\n",
    "def create_autoreg_features(df, short_term_features, num_days = 2):\n",
    "\tall_days = df.index.get_level_values(0).unique().sort_values()\n",
    "\n",
    "\tnew_df = pd.DataFrame()\n",
    "\tfor dayIndex in range(num_days, all_days.shape[0]):\n",
    "\t\tday = all_days[dayIndex]\n",
    "\n",
    "\t\tnewDayDf = df.loc[day]\n",
    "\t\tnewDayDf[\"date\"] = day\n",
    "\t\tcurrTickers = newDayDf.index.values\n",
    "\t\tfor prevIndex in range(num_days):\n",
    "\t\t\tprevDay = all_days[dayIndex - prevIndex]\n",
    "\t\t\tprevDayFeatures = df.loc[prevDay].reindex(currTickers)[short_term_features].add_suffix(f\"_prev_{prevIndex + 1}\")\n",
    "\t\t\tnewDayDf = pd.concat([newDayDf, prevDayFeatures], axis = 1)\n",
    "\t\t\n",
    "\t\tnew_df = pd.concat([new_df, newDayDf.set_index(\"date\", append = True)], axis = 0)\n",
    "\n",
    "\tautoreg_removed_rows = df.loc[all_days[:num_days]].shape[0]\n",
    "\n",
    "\tassert df.shape[0] - new_df.shape[0] == autoreg_removed_rows, \"Autoregression removed different amount of rows than expected\"\n",
    "\t\n",
    "\treturn new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreg_df = create_autoreg_features(adj_df, short_term_columns, num_days=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40727, 424)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoreg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43859, 340)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dates = ['2023-09-28', '2023-09-29', '2023-10-02', '2023-10-03', '2023-10-04',\n",
    "       '2023-10-05', '2023-10-06', '2023-10-09', '2023-10-10', '2023-10-11',\n",
    "       '2023-10-12', '2023-10-13', '2023-10-16', '2023-10-17', '2023-10-18',\n",
    "       '2023-10-19', '2023-10-20', '2023-10-24', '2023-10-25', '2023-10-26',\n",
    "       '2023-10-27', '2023-10-30', '2023-10-31', '2023-11-01', '2023-11-02',\n",
    "       '2023-11-03', '2023-11-06', '2023-11-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_date(all_dates, train_size = 0.75, days_ahead = 5):\n",
    "\tnum_dates = len(all_dates)\n",
    "\tnum_train_test_dates = num_dates - days_ahead\n",
    "\tnum_train_dates = int(num_train_test_dates * train_size)\n",
    "\n",
    "\ttrain_dates = all_dates[:num_train_dates]\n",
    "\tval_dates = all_dates[num_train_dates:num_train_dates+days_ahead]\n",
    "\ttest_dates = all_dates[num_train_dates+days_ahead:]\n",
    "\n",
    "\treturn train_dates, val_dates, test_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 5, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val, test = split_date(some_dates)\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantBearsDataAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
