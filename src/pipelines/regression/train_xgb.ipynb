{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd, warnings\n",
    "# warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "path_to_data_dir = \"../../data/\"\n",
    "\n",
    "def load_local_preprocessed_data():\n",
    "\t# X_train = pd.read_csv(path_to_data_dir + \"prep_X_train.csv\").set_index([\"date\", \"ticker\"])\n",
    "\t# X_val = pd.read_csv(path_to_data_dir + \"prep_X_val.csv\").set_index([\"date\", \"ticker\"])\n",
    "\t# X_test = pd.read_csv(path_to_data_dir + \"prep_X_test.csv\").set_index([\"date\", \"ticker\"])\n",
    "\tX_df = pd.read_csv(path_to_data_dir + \"target_adjusted_features.csv\").set_index([\"date\", \"ticker\"])\n",
    "\ttarget = pd.read_csv(path_to_data_dir + \"s&p_adjusted_target.csv\").set_index([\"date\", \"ticker\"])\n",
    "\treturn X_df, target[\"change_adj_s&p\"]\n",
    "\n",
    "def split_date(all_dates, train_size = 0.75, days_ahead = 5):\n",
    "\tnum_dates = len(all_dates)\n",
    "\tnum_train_test_dates = num_dates - days_ahead\n",
    "\tnum_train_dates = int(num_train_test_dates * train_size)\n",
    "\n",
    "\ttrain_dates = all_dates[:num_train_dates]\n",
    "\tval_dates = all_dates[num_train_dates:num_train_dates+days_ahead]\n",
    "\ttest_dates = all_dates[num_train_dates+days_ahead:]\n",
    "\n",
    "\treturn train_dates, val_dates, test_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train dates (19), val dates (5), test dates (7)\n",
      "Train shapes: ((29745, 339), (29745,))\n",
      "Val shapes: ((7778, 339), (7778,))\n",
      "Test shapes: ((11263, 339), (11263,))\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_df, y_series = load_local_preprocessed_data()\n",
    "\n",
    "train_dates, val_dates, test_dates = split_date(X_df.index.get_level_values(0).unique().sort_values()[2:])\n",
    "print(f\"# of train dates ({len(train_dates)}), val dates ({len(val_dates)}), test dates ({len(test_dates)})\")\n",
    "\n",
    "X_train, y_train = X_df.loc[train_dates], y_series.loc[train_dates]\n",
    "X_val, y_val = X_df.loc[val_dates], y_series.loc[val_dates]\n",
    "X_test, y_test = X_df.loc[test_dates], y_series.loc[test_dates]\n",
    "\n",
    "print(f\"Train shapes: {X_train.shape, y_train.shape}\")\n",
    "print(f\"Val shapes: {X_val.shape, y_val.shape}\")\n",
    "print(f\"Test shapes: {X_test.shape, y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "onehot_features = [\"sector\", \"area\"]\n",
    "standard_scale_features = [f for f in X_train.columns.values if f not in onehot_features]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers = [\n",
    "\t\t(\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), onehot_features),\n",
    "\t\t(\"std\", StandardScaler(), standard_scale_features)\n",
    "\t]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def xgb_RMSE(model_name, model_algo, preprocessor, X_other, y_other, X_test, y_test, param_grid, moving_train_window = False):\n",
    "\t# lists to be returned \n",
    "\trmse_scores = {}\n",
    "\tr2_scores = {}\n",
    "\tscore_deviations = {}\n",
    "\tbest_params = {}\n",
    "\tbest_models = {}\n",
    "\n",
    "\ttime_split = TimeSeriesSplit(n_splits=5, test_size = 1, gap = 5)\n",
    "\n",
    "\tall_dates = X_other.index.get_level_values(0).unique().sort_values()\n",
    "\n",
    "\tparam_grid = dict(item for item in param_grid.items() if model_name in item[0])\n",
    "\n",
    "\t# your code here...\n",
    "\tfor i, (train_date_idx, val_date_idx) in enumerate(time_split.split(X_other.index.get_level_values(0).unique())):\n",
    "\t\t\t\n",
    "\t\t\t# print(\"Split shapes\")\n",
    "\t\t\t# print(X_other.shape, X_test.shape)\n",
    "\n",
    "\t\t\tif moving_train_window:\n",
    "\t\t\t\ttrain_date_idx = train_date_idx[-10:]\n",
    "\n",
    "\t\t\ttrain_dates = all_dates[train_date_idx]\n",
    "\t\t\tval_date = all_dates[val_date_idx]\n",
    "\n",
    "\t\t\ttrain_set_X = X_other.loc[train_dates]\n",
    "\t\t\ttrain_set_y = y_other.loc[train_dates]\n",
    "\n",
    "\t\t\tval_set_X = X_other.loc[val_date]\n",
    "\t\t\tval_set_y = y_other.loc[val_date]\n",
    "\n",
    "\t\t\tother_set_X = pd.concat([train_set_X, val_set_X], axis = 0).reset_index(drop = True)\n",
    "\t\t\tother_set_y = pd.concat([train_set_y, val_set_y], axis = 0).reset_index(drop = True)\n",
    "\n",
    "\t\t\t# Prevent automatic CV with GridSearchCV\n",
    "\t\t\tps = PredefinedSplit(([-1] * train_set_X.shape[0]) + ([1] * val_set_X.shape[0]))\n",
    "\n",
    "\t\t\tpipe = make_pipeline(preprocessor, model_algo)\n",
    "\n",
    "\t\t\tgrid = GridSearchCV(\n",
    "\t\t\t\t\tpipe, cv = ps, param_grid = param_grid, scoring = \"neg_mean_squared_error\",\n",
    "\t\t\t\t\treturn_train_score = True, verbose = True, refit=False)\n",
    "\n",
    "\t\t\tgrid.fit(other_set_X, other_set_y)\n",
    "\n",
    "\t\t\tprint(f\"Best params for val date: {val_date[0]}\")\n",
    "\t\t\tprint(grid.best_params_)\n",
    "\n",
    "\t\t\ttruths = [train_set_y, val_set_y, y_test]\n",
    "\n",
    "\t\t\tpipe.set_params(**grid.best_params_)\n",
    "\n",
    "\t\t\tpipe.fit(train_set_X, train_set_y)\n",
    "\n",
    "\t\t\tpreds = list(map(lambda v: pipe.predict(v), [train_set_X, val_set_X, X_test]))\n",
    "\n",
    "\t\t\ttrain_rmse, val_rmse, test_rmse = list(\n",
    "\t\t\t\tmap(\n",
    "\t\t\t\t\tlambda x: mean_squared_error(x[0], x[1], squared=False),\n",
    "\t\t\t\t\tzip(truths, preds)))\n",
    "\n",
    "\t\t\ttrain_r2, val_r2, test_r2 = list(\n",
    "\t\t\t\tmap(\n",
    "\t\t\t\t\tlambda x: r2_score(x[0], x[1]),\n",
    "\t\t\t\t\tzip(truths, preds)))\n",
    "\t\t\t\n",
    "\t\t\ttrain_stddev, val_stddev, test_stddev = list(\n",
    "\t\t\t\tmap(\n",
    "\t\t\t\t\tlambda pred: pred.std(),\n",
    "\t\t\t\t\tpreds))\n",
    "\n",
    "\t\t\tprint(f\"RMSE for best estimator:\")\n",
    "\t\t\tprint(f\"Train: {train_rmse:.6f}\")\n",
    "\t\t\tprint(f\"Val: {val_rmse:.6f}\")\n",
    "\t\t\tprint(f\"Test: {test_rmse:.6f}\")\n",
    "\t\t\tprint(f\"R2 for best estimator:\")\n",
    "\t\t\tprint(f\"Train: {train_r2:.6f}\")\n",
    "\t\t\tprint(f\"Val: {val_r2:.6f}\")\n",
    "\t\t\tprint(f\"Test: {test_r2:.6f}\")\n",
    "\t\t\tprint(f\"Stddev for best estimator:\")\n",
    "\t\t\tprint(f\"Train: {train_stddev:.6f}\")\n",
    "\t\t\tprint(f\"Val: {val_stddev:.6f}\")\n",
    "\t\t\tprint(f\"Test: {test_stddev:.6f}\")\n",
    "\t\t\t\n",
    "\n",
    "\t\t\trmse_scores[val_date[0]] = [train_rmse, val_rmse, test_rmse]\n",
    "\t\t\tr2_scores[val_date[0]] = [train_r2, val_r2, test_r2]\n",
    "\t\t\tscore_deviations[val_date[0]] = [train_stddev, val_stddev, test_stddev]\n",
    "\t\t\tbest_params[val_date[0]] = grid.best_params_\n",
    "\t\t\tbest_models[val_date[0]] = pipe\n",
    "\n",
    "\treturn rmse_scores, r2_scores, score_deviations, best_params, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_other = pd.concat([X_train, X_val], axis = 0)\n",
    "y_other = pd.concat([y_train, y_val], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbregressor\n",
      "Fitting 1 folds for each of 27 candidates, totalling 27 fits\n",
      "Best params for val date: 2023-10-30\n",
      "{'xgbregressor__learning_rate': 1e-07, 'xgbregressor__max_depth': 5, 'xgbregressor__n_estimators': 100, 'xgbregressor__reg_lambda': 1.0, 'xgbregressor__subsample': None}\n",
      "RMSE for best estimator:\n",
      "Train: 0.140791\n",
      "Val: 0.074975\n",
      "Test: 0.065115\n",
      "R2 for best estimator:\n",
      "Train: 0.000009\n",
      "Val: -0.093313\n",
      "Test: -0.001664\n",
      "Stddev for best estimator:\n",
      "Train: 0.000001\n",
      "Val: 0.000000\n",
      "Test: 0.000000\n",
      "Fitting 1 folds for each of 27 candidates, totalling 27 fits\n",
      "Best params for val date: 2023-10-31\n",
      "{'xgbregressor__learning_rate': 1e-07, 'xgbregressor__max_depth': 5, 'xgbregressor__n_estimators': 100, 'xgbregressor__reg_lambda': 1.0, 'xgbregressor__subsample': 0.5}\n",
      "RMSE for best estimator:\n",
      "Train: 0.140851\n",
      "Val: 0.067793\n",
      "Test: 0.065227\n",
      "R2 for best estimator:\n",
      "Train: 0.000004\n",
      "Val: -0.015419\n",
      "Test: -0.005116\n",
      "Stddev for best estimator:\n",
      "Train: 0.000000\n",
      "Val: 0.000000\n",
      "Test: 0.000000\n",
      "Fitting 1 folds for each of 27 candidates, totalling 27 fits\n",
      "Best params for val date: 2023-11-01\n",
      "{'xgbregressor__learning_rate': 1e-07, 'xgbregressor__max_depth': 5, 'xgbregressor__n_estimators': 100, 'xgbregressor__reg_lambda': 1.0, 'xgbregressor__subsample': 0.5}\n",
      "RMSE for best estimator:\n",
      "Train: 0.140714\n",
      "Val: 0.071308\n",
      "Test: 0.065157\n",
      "R2 for best estimator:\n",
      "Train: 0.000004\n",
      "Val: -0.019233\n",
      "Test: -0.002959\n",
      "Stddev for best estimator:\n",
      "Train: 0.000000\n",
      "Val: 0.000000\n",
      "Test: 0.000000\n",
      "Fitting 1 folds for each of 27 candidates, totalling 27 fits\n",
      "Best params for val date: 2023-11-02\n",
      "{'xgbregressor__learning_rate': 1e-07, 'xgbregressor__max_depth': 5, 'xgbregressor__n_estimators': 100, 'xgbregressor__reg_lambda': 1.0, 'xgbregressor__subsample': None}\n",
      "RMSE for best estimator:\n",
      "Train: 0.141158\n",
      "Val: 0.075715\n",
      "Test: 0.065397\n",
      "R2 for best estimator:\n",
      "Train: 0.000009\n",
      "Val: -0.167608\n",
      "Test: -0.010371\n",
      "Stddev for best estimator:\n",
      "Train: 0.000001\n",
      "Val: 0.000000\n",
      "Test: 0.000000\n",
      "Fitting 1 folds for each of 27 candidates, totalling 27 fits\n",
      "Best params for val date: 2023-11-03\n",
      "{'xgbregressor__learning_rate': 0.001, 'xgbregressor__max_depth': 5, 'xgbregressor__n_estimators': 1000, 'xgbregressor__reg_lambda': 1.0, 'xgbregressor__subsample': 0.5}\n",
      "RMSE for best estimator:\n",
      "Train: 0.114926\n",
      "Val: 0.064375\n",
      "Test: 0.067408\n",
      "R2 for best estimator:\n",
      "Train: 0.343892\n",
      "Val: -0.031562\n",
      "Test: -0.073461\n",
      "Stddev for best estimator:\n",
      "Train: 0.028978\n",
      "Val: 0.007302\n",
      "Test: 0.007379\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.linear_model import ElasticNet, LinearRegression, BayesianRidge\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "\n",
    "models = [\n",
    "\t(\"xgbregressor\", XGBRegressor()),\n",
    "\t# (\"elasticnet\", ElasticNet()),\n",
    "\t# (\"bayesianridge\", BayesianRidge()),\n",
    "\t# (\"kneighborsregressor\", KNeighborsRegressor()),\n",
    "\t# (\"randomforestregressor\", RandomForestRegressor()),\n",
    "\t# (\"adaboostregressor\", AdaBoostRegressor())\n",
    "]\n",
    "\n",
    "total_param_grid = {\n",
    "\t\"xgbregressor__n_estimators\": [100, 500, 1000],\n",
    "\t'xgbregressor__learning_rate': [1e-3, 1e-5, 1e-7],\n",
    "\t\"xgbregressor__reg_lambda\": [0.1, 1.0, 10.0],\n",
    "\t\"xgbregressor__subsample\": [0.5, 0.7, None],\n",
    "\t\"xgbregressor__max_depth\": [3, 5, 7],\n",
    "\n",
    "\t# \"randomforestregressor__n_estimators\": [100, 250, 500],\n",
    "\t# \"randomforestregressor__max_features\": [\"log2\"],\n",
    "\t# \"randomforestregressor__criterion\": [\"poisson\", \"friedman_mse\"],\n",
    "\t# \"randomforestregressor__max_samples\": [0.5, 0.7],\n",
    "\n",
    "\t# \"elasticnet__alpha\": [0.001, .01, .1, 1.0, 10.0],\n",
    "\t# \"elasticnet__l1_ratio\": [.01, .1, .7, .9],\n",
    "\n",
    "\t# \"bayesianridge__alpha_1\": [1e-10, 1e-8, 1e-5, 1e-2],\n",
    "\t# \"bayesianridge__alpha_2\": [1e-10, 1e-8, 1e-5, 1e-2],\n",
    "\t# \"bayesianridge__lambda_1\": [1e-10, 1e-8, 1e-5, 1e-2],\n",
    "\t# \"bayesianridge__lambda_2\": [1e-10, 1e-8, 1e-5, 1e-2],\n",
    "\n",
    "\t# \"kneighborsregressor__n_neighbors\": [50, 100, 150, 200, 300, 500, 700, 1000],\n",
    "\t# \"kneighborsregressor__weights\": [\"uniform\", \"distance\"],\n",
    "}\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for model_name, model_algo in models:\n",
    "\tprint(model_name)\n",
    "\tgrid_result = xgb_RMSE(model_name, model_algo, preprocessor, X_other, y_other, X_test, y_test, total_param_grid, moving_train_window=True)\n",
    "\tall_results[model_name] = grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonData = {}\n",
    "\n",
    "for model_name, _ in models:\n",
    "\trmse_scores, r2_scores, score_deviations, best_params, best_models = all_results[model_name]\n",
    "\tjsonData[model_name] = {\n",
    "\t\t\"rmse_scores\": rmse_scores,\n",
    "\t\t\"r2_scores\": r2_scores,\n",
    "\t\t\"pred_deviations\": score_deviations,\n",
    "\t\t\"best_params\": best_params\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbregressor': {'rmse_scores': {'2023-10-30': [0.14079103788650682,\n",
       "    0.07497538867205285,\n",
       "    0.06511474749598006],\n",
       "   '2023-10-31': [0.14085113700586413,\n",
       "    0.06779320343915794,\n",
       "    0.06522685021272046],\n",
       "   '2023-11-01': [0.14071438118205803,\n",
       "    0.07130837016382845,\n",
       "    0.06515681552319047],\n",
       "   '2023-11-02': [0.14115770657086965,\n",
       "    0.07571476985418321,\n",
       "    0.06539711716379852],\n",
       "   '2023-11-03': [0.11492555175521657,\n",
       "    0.06437493169358369,\n",
       "    0.06740798779487335]},\n",
       "  'r2_scores': {'2023-10-30': [8.948979964173986e-06,\n",
       "    -0.09331304770325155,\n",
       "    -0.001664465172172891],\n",
       "   '2023-10-31': [4.4174338178493144e-06,\n",
       "    -0.01541891026921216,\n",
       "    -0.005116401078331112],\n",
       "   '2023-11-01': [4.151373070748754e-06,\n",
       "    -0.019233260606708713,\n",
       "    -0.002959153747312371],\n",
       "   '2023-11-02': [8.938307550998559e-06,\n",
       "    -0.16760843494544275,\n",
       "    -0.010370724179547208],\n",
       "   '2023-11-03': [0.34389243522897517,\n",
       "    -0.031562367304188044,\n",
       "    -0.0734610029261551]},\n",
       "  'pred_deviations': {'2023-10-30': [6.791222e-07,\n",
       "    1.6157719e-07,\n",
       "    1.733014e-07],\n",
       "   '2023-10-31': [3.384886e-07, 1.2544972e-07, 1.3561936e-07],\n",
       "   '2023-11-01': [3.1749326e-07, 1.186079e-07, 1.1968535e-07],\n",
       "   '2023-11-02': [6.807034e-07, 1.7074238e-07, 1.7055397e-07],\n",
       "   '2023-11-03': [0.028977731, 0.007301983, 0.0073790494]},\n",
       "  'best_params': {'2023-10-30': {'xgbregressor__learning_rate': 1e-07,\n",
       "    'xgbregressor__max_depth': 5,\n",
       "    'xgbregressor__n_estimators': 100,\n",
       "    'xgbregressor__reg_lambda': 1.0,\n",
       "    'xgbregressor__subsample': None},\n",
       "   '2023-10-31': {'xgbregressor__learning_rate': 1e-07,\n",
       "    'xgbregressor__max_depth': 5,\n",
       "    'xgbregressor__n_estimators': 100,\n",
       "    'xgbregressor__reg_lambda': 1.0,\n",
       "    'xgbregressor__subsample': 0.5},\n",
       "   '2023-11-01': {'xgbregressor__learning_rate': 1e-07,\n",
       "    'xgbregressor__max_depth': 5,\n",
       "    'xgbregressor__n_estimators': 100,\n",
       "    'xgbregressor__reg_lambda': 1.0,\n",
       "    'xgbregressor__subsample': 0.5},\n",
       "   '2023-11-02': {'xgbregressor__learning_rate': 1e-07,\n",
       "    'xgbregressor__max_depth': 5,\n",
       "    'xgbregressor__n_estimators': 100,\n",
       "    'xgbregressor__reg_lambda': 1.0,\n",
       "    'xgbregressor__subsample': None},\n",
       "   '2023-11-03': {'xgbregressor__learning_rate': 0.001,\n",
       "    'xgbregressor__max_depth': 5,\n",
       "    'xgbregressor__n_estimators': 1000,\n",
       "    'xgbregressor__reg_lambda': 1.0,\n",
       "    'xgbregressor__subsample': 0.5}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"xgb_cv_results_moving_window.json\", \"w\") as cv_json:\n",
    "\tjson.dump(jsonData, cv_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantBearsDataAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
