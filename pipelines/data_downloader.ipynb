{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd, warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "short_term_columns = ['analysts_down', 'analysts_down_percent', 'analysts_up_percent',\n",
    "       'authors_count', 'capm_alpha_60m', 'coefficient_of_variation_90d',\n",
    "       'debt_eq', 'div_growth_category', 'div_safety_category',\n",
    "       'dividends_estimate_fy1_analyst_down',\n",
    "       'dividends_estimate_fy1_analyst_up',\n",
    "       'dividends_estimate_fy2_analyst_down',\n",
    "       'dividends_estimate_fy2_analyst_up',\n",
    "       'dps_consensus_mean_percent_revisions_down_1_annual_period_fwd',\n",
    "       'eps_ltg', 'last_price_vs_sma_100d', 'last_price_vs_sma_10d',\n",
    "       'last_price_vs_sma_200d', 'last_price_vs_sma_50d', 'momentum_12m',\n",
    "       'momentum_3m', 'momentum_6m', 'momentum_9m', 'pb_ratio',\n",
    "       'price_return_1y', 'price_return_3m', 'price_return_6m',\n",
    "       'price_return_9m', 'return_on_net_tangible_assets',\n",
    "       'return_on_total_capital', 'Future_3-5Y_EPS_without_NRI_Growth_Rate',\n",
    "       'moment_rank', '5-Day_RSI', '9-Day_RSI', '14-Day_RSI',\n",
    "       '6-1_Month_Momentum_%', '12-1_Month_Momentum_%', 'ratios_rank',\n",
    "       'Forward_PE_Ratio', 'EV-to-Forward-EBITDA',\n",
    "       'Earnings_Yield__Greenblatt__%', 'Volume']\n",
    "\n",
    "accessKeys = pd.read_csv(\"../quant-bears_accessKeys.csv\")\n",
    "session = boto3.Session(\n",
    "\taws_access_key_id=accessKeys.loc[0, \"Access key ID\"],\n",
    "\taws_secret_access_key=accessKeys.loc[0, \"Secret access key\"]\n",
    ")\n",
    "\n",
    "s3_collection_path = \"s3://quant-bears-data-collection/raw-data/\"\n",
    "s3_price_collection_path = \"s3://quant-bears-data-collection/raw-resolved-price/\"\n",
    "\n",
    "def load_data():\n",
    "\tdata_sources = [\"seekingAlpha.seekingAlphaBulkMetrics\", \"gurufocus\"]\n",
    "\tsources_dict = dict((source, wr.s3.list_objects(s3_collection_path + source + \"/\", boto3_session=session)) for source in data_sources)\n",
    "\tdf_dict = {}\n",
    "\tfor source in data_sources:\n",
    "\t\tdfs = []\n",
    "\t\tprint(source)\n",
    "\t\tfor path in tqdm(sources_dict[source]):\n",
    "\t\t\tnew_df = wr.s3.read_parquet(path, boto3_session=session)\n",
    "\t\t\tnew_df[\"date\"] = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\t\t\tdfs.append(new_df)\n",
    "\n",
    "\t\tdf_dict[source] = pd.concat(dfs, axis = 0)\n",
    "\tjoined_df = pd.concat([df.set_index([\"date\", \"ticker\"]) for df in df_dict.values()], axis = 1)\n",
    "\treturn joined_df\n",
    "\n",
    "def load_pred_price(df, days_ahead=5, diff = True):\n",
    "\tall_dates = df.index.get_level_values(0).unique()\n",
    "\tadjusted_dates = all_dates[:-days_ahead]\n",
    "\tadjusted_df = df.loc[adjusted_dates]\n",
    "\n",
    "\tpred_dates = all_dates[days_ahead:]\n",
    "\tdfs = []\n",
    "\tfor i, d in enumerate(tqdm(pred_dates)):\n",
    "\t\tpath = s3_price_collection_path + d + \".parquet\"\n",
    "\t\tnew_df = wr.s3.read_parquet(path, boto3_session=session)\n",
    "\n",
    "\t\ts = df.loc[all_dates[i], \"primary_price\"]\n",
    "\t\tintersect_tickers = np.intersect1d(new_df[\"ticker\"].values, s[~s.isna()].index.values)\n",
    "\t\tnew_df = new_df[new_df[\"ticker\"].isin(intersect_tickers)]\n",
    "\t\tnew_df[\"date\"] = all_dates[i]\n",
    "\t\tdfs.append(new_df)\n",
    "\n",
    "\tprice_df = pd.concat(dfs, axis = 0).set_index([\"date\", \"ticker\"]).rename({\"primary_price\": \"pred_price\"}, axis = 1)\n",
    "\n",
    "\tif diff:\n",
    "\t\ta_df = adjusted_df.reindex(price_df.index)\n",
    "\t\treturn a_df, pd.Series((price_df[\"pred_price\"] - a_df[\"primary_price\"]) / a_df[\"primary_price\"], index=price_df.index)\n",
    "\treturn adjusted_df.reindex(price_df.index), price_df\n",
    "\n",
    "def split_date(all_dates, train_size = 0.75, days_ahead = 5):\n",
    "\tnum_dates = len(all_dates)\n",
    "\tnum_train_test_dates = num_dates - days_ahead\n",
    "\tnum_train_dates = int(num_train_test_dates * train_size)\n",
    "\n",
    "\ttrain_dates = all_dates[:num_train_dates]\n",
    "\tval_dates = all_dates[num_train_dates:num_train_dates+days_ahead]\n",
    "\ttest_dates = all_dates[num_train_dates+days_ahead:]\n",
    "\n",
    "\treturn train_dates, val_dates, test_dates\n",
    "\n",
    "def create_autoreg_features(df, short_term_features, num_days = 2):\n",
    "\tall_days = df.index.get_level_values(0).unique().sort_values()\n",
    "\n",
    "\tnew_df = pd.DataFrame()\n",
    "\tfor dayIndex in range(num_days, all_days.shape[0]):\n",
    "\t\tday = all_days[dayIndex]\n",
    "\n",
    "\t\tnewDayDf = df.loc[day]\n",
    "\t\tnewDayDf[\"date\"] = day\n",
    "\t\tcurrTickers = newDayDf.index.values\n",
    "\t\tfor prevIndex in range(num_days):\n",
    "\t\t\tprevDay = all_days[dayIndex - prevIndex]\n",
    "\t\t\tprevDayFeatures = df.loc[prevDay].reindex(currTickers)[short_term_features].add_suffix(f\"_prev_{prevIndex + 1}\")\n",
    "\t\t\tnewDayDf = pd.concat([newDayDf, prevDayFeatures], axis = 1)\n",
    "\t\t\n",
    "\t\tnew_df = pd.concat([new_df, newDayDf.set_index(\"date\", append = True)], axis = 0)\n",
    "\n",
    "\tautoreg_removed_rows = df.loc[all_days[:num_days]].shape[0]\n",
    "\n",
    "\tassert df.shape[0] - new_df.shape[0] == autoreg_removed_rows, \"Autoregression removed different amount of rows than expected\"\n",
    "\t\n",
    "\treturn new_df.reorder_levels([1, 0]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seekingAlpha.seekingAlphaBulkMetrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:39<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gurufocus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:24<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (60290, 339)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:15<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post loaded pred price: ((51918, 339), (51918,))\n",
      "# of train dates (21), val dates (5), test dates (7)\n",
      "Train shapes: ((32877, 339), (32877,))\n",
      "Val shapes: ((7778, 339), (7778,))\n",
      "Test shapes: ((11263, 339), (11263,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "df = load_data()\n",
    "print(f\"Loaded data shape: {df.shape}\")\n",
    "autoreg_df = df\n",
    "# autoreg_df = create_autoreg_features(df, short_term_columns, num_days=2)\n",
    "# print(f\"Post autoregressive: {autoreg_df.shape}\")\n",
    "X_df, y_series = load_pred_price(autoreg_df, days_ahead = 5, diff = True)\n",
    "print(f\"Post loaded pred price: {X_df.shape, y_series.shape}\")\n",
    "\n",
    "train_dates, val_dates, test_dates = split_date(X_df.index.get_level_values(0).unique().sort_values())\n",
    "print(f\"# of train dates ({len(train_dates)}), val dates ({len(val_dates)}), test dates ({len(test_dates)})\")\n",
    "\n",
    "X_df = X_df.fillna({\"sector\": \"none\", \"area\": \"none\"})\n",
    "\n",
    "X_train, y_train = X_df.loc[train_dates], y_series.loc[train_dates]\n",
    "X_val, y_val = X_df.loc[val_dates], y_series.loc[val_dates]\n",
    "X_test, y_test = X_df.loc[test_dates], y_series.loc[test_dates]\n",
    "\n",
    "print(f\"Train shapes: {X_train.shape, y_train.shape}\")\n",
    "print(f\"Val shapes: {X_val.shape, y_val.shape}\")\n",
    "print(f\"Test shapes: {X_test.shape, y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('2023-09-28',    'A'),\n",
       "            ('2023-09-28',   'AA'),\n",
       "            ('2023-09-28',  'AAL'),\n",
       "            ('2023-09-28',  'AAP'),\n",
       "            ('2023-09-28', 'AAPL'),\n",
       "            ('2023-09-28', 'ABBV'),\n",
       "            ('2023-09-28', 'ABCL'),\n",
       "            ('2023-09-28', 'ABCM'),\n",
       "            ('2023-09-28', 'ABEV'),\n",
       "            ('2023-09-28',  'ABM'),\n",
       "            ...\n",
       "            ('2023-11-21',   'ZI'),\n",
       "            ('2023-11-21', 'ZION'),\n",
       "            ('2023-11-21',  'ZIP'),\n",
       "            ('2023-11-21',   'ZM'),\n",
       "            ('2023-11-21',   'ZS'),\n",
       "            ('2023-11-21',  'ZTO'),\n",
       "            ('2023-11-21',  'ZTS'),\n",
       "            ('2023-11-21',  'ZUO'),\n",
       "            ('2023-11-21',  'ZWS'),\n",
       "            ('2023-10-17',  'NCR')],\n",
       "           names=['date', 'ticker'], length=60290)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/raw_features.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.to_csv(\"../data/targe_adjusted_features.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_series.rename(\"target\").to_csv(\"../data/target.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantBearsDataAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
